/**
 * OpenAIService - OpenAI API integration for Book Buddy
 * Extends APIService base class and integrates with AI utilities
 * Follows Book Buddy architecture patterns and TDD requirements
 */

import APIService from './APIService.js';
import { eventBus, EVENTS } from '../../utils/EventBus.js';

export default class OpenAIService extends APIService {
    constructor(config = {}) {
        // Initialize base API service with OpenAI endpoint
        super('https://api.openai.com/v1', {
            timeout: config.timeout || 30000,
            retries: config.retries || 3,
            retryDelay: config.retryDelay || 1000,
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${config.apiKey || ''}`,
                'User-Agent': 'BookBuddy/1.0'
            }
        });

        // Configuration validation
        if (!config.apiKey || config.apiKey.trim().length === 0) {
            console.error('‚ùå OpenAI API key is required');
            this.isValid = false;
            return;
        }

        // Core configuration
        this.config = {
            apiKey: config.apiKey,
            baseURL: 'https://api.openai.com/v1',
            defaultModel: {
                name: config.defaultModel || 'gpt-3.5-turbo',
                maxTokens: config.defaultMaxTokens || 4096,
                temperature: config.defaultTemperature || 0.7
            },
            timeout: config.timeout || 30000,
            maxRetries: config.retries || 3,
            
            // Cost and usage limits
            costLimits: {
                perRequest: config.maxCostPerRequest || 1.00,
                perHour: config.maxCostPerHour || 10.00,
                perDay: config.maxCostPerDay || 50.00
            },
            
            // Model configurations
            models: {
                'gpt-4': { maxTokens: 8192, costPerToken: 0.00003 },
                'gpt-4-turbo': { maxTokens: 128000, costPerToken: 0.00001 },
                'gpt-3.5-turbo': { maxTokens: 4096, costPerToken: 0.000002 },
                'gpt-3.5-turbo-16k': { maxTokens: 16384, costPerToken: 0.000004 }
            },
            
            // Feature flags
            features: {
                enableStreaming: config.enableStreaming !== false,
                enableBatchProcessing: config.enableBatchProcessing !== false,
                enableContentFiltering: config.enableContentFiltering !== false,
                enableCostTracking: config.enableCostTracking !== false
            },
            
            // Security settings
            security: {
                enableInputSanitization: config.enableInputSanitization !== false,
                enableContentFilter: config.enableContentFilter !== false,
                maxPromptLength: config.maxPromptLength || 50000
            }
        };

        // Utilities integration - will be injected
        this.tokenManager = null;
        this.rateLimiter = null;
        this.promptTemplates = null;

        // Internal state
        this.state = {
            initialized: false,
            totalRequests: 0,
            totalCost: 0,
            totalTokens: 0,
            errors: [],
            performance: {
                responseTimes: [],
                averageResponseTime: 0,
                minResponseTime: Infinity,
                maxResponseTime: 0
            }
        };

        // EventBus integration
        this.eventBus = eventBus;
        this.isValid = true;

        console.log('ü§ñ OpenAIService initialized');
    }

    /**
     * Initialize service with utility dependencies
     */
    async initialize(tokenManager, rateLimiter, promptTemplates) {
        try {
            // Inject dependencies
            this.tokenManager = tokenManager;
            this.rateLimiter = rateLimiter;
            this.promptTemplates = promptTemplates;

            // Validate API key
            const keyValidation = await this.validateAPIKey();
            if (!keyValidation.valid) {
                throw new Error(`Invalid OpenAI API key: ${keyValidation.message}`);
            }

            // Setup event listeners
            this.setupEventListeners();

            this.state.initialized = true;
            console.log('‚úÖ OpenAIService initialized successfully');

            // Emit initialization event
            this.eventBus.emit('ai:service:initialized', {
                service: 'OpenAI',
                models: Object.keys(this.config.models),
                features: this.config.features
            });

            return { success: true, message: 'OpenAI service initialized successfully' };

        } catch (error) {
            console.error('‚ùå OpenAI service initialization failed:', error);
            this.isValid = false;
            return { success: false, message: error.message };
        }
    }

    /**
     * Setup event listeners for Book Buddy integration
     */
    setupEventListeners() {
        // Listen for book analysis requests
        this.eventBus.on('ai:analyze:book', async (data) => {
            await this.analyzeBook(data.book, data.analysisType, data.options);
        });

        // Listen for batch analysis requests
        this.eventBus.on('ai:analyze:batch', async (data) => {
            await this.processBatch(data.requests, data.options);
        });

        // Listen for usage limit alerts
        this.eventBus.on('ai:usage:warning', (data) => {
            console.warn('‚ö†Ô∏è AI usage warning:', data);
        });

        console.log('üîó OpenAI event listeners configured');
    }

    /**
     * Core completion method - main API interface
     */
    async completion(request) {
        if (!this.state.initialized) {
            return this.createErrorResponse('Service not initialized');
        }

        try {
            const startTime = Date.now();

            // Validate and prepare request
            const validationResult = await this.validateRequest(request);
            if (!validationResult.valid) {
                return this.createErrorResponse(validationResult.error);
            }

            const preparedRequest = validationResult.request;

            // Check rate limits
            const rateLimitCheck = await this.checkRateLimit(preparedRequest);
            if (!rateLimitCheck.allowed) {
                return this.handleRateLimitResponse(rateLimitCheck);
            }

            // Estimate and check cost
            const costEstimate = await this.estimateRequestCost(preparedRequest);
            if (costEstimate.cost > this.config.costLimits.perRequest) {
                return this.createErrorResponse(`Request cost ${costEstimate.cost.toFixed(4)} exceeds limit ${this.config.costLimits.perRequest}`);
            }

            // Build API request
            const apiRequest = await this.buildAPIRequest(preparedRequest);

            // Emit request start event
            this.eventBus.emit('ai:request:started', {
                requestId: apiRequest.requestId,
                model: preparedRequest.model,
                estimatedCost: costEstimate.cost
            });

            // Make API call
            const apiResponse = await this.request('/chat/completions', {
                method: 'POST',
                body: JSON.stringify(apiRequest.body)
            });

            const endTime = Date.now();
            const responseTime = endTime - startTime;

            // Process response
            if (apiResponse.success) {
                const result = await this.processSuccessResponse(
                    apiResponse.data, 
                    preparedRequest, 
                    costEstimate,
                    responseTime,
                    apiRequest.requestId
                );

                // Record usage
                await this.recordUsage(result.usage, preparedRequest.model);

                // Update performance metrics
                this.updatePerformanceMetrics(responseTime);

                // Emit success event
                this.eventBus.emit('ai:request:completed', {
                    requestId: apiRequest.requestId,
                    success: true,
                    usage: result.usage,
                    responseTime
                });

                return result;

            } else {
                return await this.handleAPIError(apiResponse, preparedRequest, apiRequest.requestId);
            }

        } catch (error) {
            console.error('‚ùå OpenAI completion error:', error);
            return this.createErrorResponse(`Completion failed: ${error.message}`);
        }
    }

    /**
     * Streaming completion support
     */
    async streamCompletion(request) {
        if (!this.config.features.enableStreaming) {
            return this.createErrorResponse('Streaming not enabled');
        }

        const streamRequest = { ...request, stream: true };
        
        try {
            // Validate request
            const validationResult = await this.validateRequest(streamRequest);
            if (!validationResult.valid) {
                return this.createErrorResponse(validationResult.error);
            }

            // Check rate limits
            const rateLimitCheck = await this.checkRateLimit(streamRequest);
            if (!rateLimitCheck.allowed) {
                return this.handleRateLimitResponse(rateLimitCheck);
            }

            // Build streaming request
            const apiRequest = await this.buildAPIRequest(streamRequest);
            
            // Return streaming response handler
            return {
                success: true,
                stream: true,
                requestId: apiRequest.requestId,
                chunks: await this.processStreamingResponse(apiRequest)
            };

        } catch (error) {
            console.error('‚ùå Streaming completion error:', error);
            return this.createErrorResponse(`Streaming failed: ${error.message}`);
        }
    }

    /**
     * Chat completion with message history
     */
    async chatCompletion(messages, options = {}) {
        const request = {
            messages,
            model: options.model || this.config.defaultModel.name,
            maxTokens: options.maxTokens || this.config.defaultModel.maxTokens,
            temperature: options.temperature || this.config.defaultModel.temperature,
            systemMessage: options.systemMessage,
            ...options
        };

        return await this.completion(request);
    }

    /**
     * Book analysis integration
     */
    async analyzeBook(bookData, analysisType, options = {}) {
        try {
            console.log(`üìö Analyzing book: ${bookData.title} (${analysisType})`);

            // Generate prompt from template
            const templateResult = await this.generateFromTemplate('analysis', analysisType, {
                title: bookData.title,
                author: bookData.author || 'Unknown Author',
                content: bookData.content,
                contentPreview: bookData.content ? bookData.content.substring(0, 2000) : '',
                wordCount: bookData.wordCount || 0,
                genre: bookData.genre || 'Unknown',
                ...options.additionalVariables
            });

            if (!templateResult.success) {
                return this.createErrorResponse(`Template generation failed: ${templateResult.error}`);
            }

            // Prepare analysis request
            const analysisRequest = {
                prompt: templateResult.prompt,
                model: options.model || this.selectOptimalModel(bookData, analysisType),
                maxTokens: options.maxTokens || this.calculateOptimalTokens(analysisType),
                temperature: options.temperature || this.getAnalysisTemperature(analysisType),
                analysisType,
                bookId: bookData.id
            };

            // Perform analysis
            const result = await this.completion(analysisRequest);

            if (result.success) {
                // Enhance result with analysis metadata
                result.analysisType = analysisType;
                result.bookData = {
                    id: bookData.id,
                    title: bookData.title,
                    author: bookData.author
                };
                result.generatedAt = new Date().toISOString();

                // Emit analysis completed event
                this.eventBus.emit('ai:analysis:completed', {
                    bookId: bookData.id,
                    analysisType,
                    success: true,
                    cost: result.cost,
                    usage: result.usage
                });

                console.log(`‚úÖ Book analysis completed: ${analysisType} for ${bookData.title}`);
            }

            return result;

        } catch (error) {
            console.error('‚ùå Book analysis error:', error);
            
            // Emit analysis error event
            this.eventBus.emit('ai:analysis:error', {
                bookId: bookData.id,
                analysisType,
                error: error.message
            });

            return this.createErrorResponse(`Book analysis failed: ${error.message}`);
        }
    }

    /**
     * Library-wide analysis
     */
    async analyzeLibrary(books, options = {}) {
        try {
            console.log(`üìö Analyzing library: ${books.length} books`);

            const analysisTypes = options.analysisTypes || ['summary'];
            const requests = [];

            // Generate requests for each book and analysis type
            for (const book of books) {
                for (const analysisType of analysisTypes) {
                    requests.push({
                        bookData: book,
                        analysisType,
                        options: {
                            ...options,
                            priority: options.priority || 'normal'
                        }
                    });
                }
            }

            // Process batch
            const batchResult = await this.processBatch(requests, {
                maxConcurrent: options.maxConcurrent || 3,
                costLimit: options.costLimit || this.config.costLimits.perHour
            });

            // Aggregate results by book
            const libraryResults = this.aggregateLibraryResults(batchResult.results, books);

            return {
                success: true,
                libraryResults,
                totalBooks: books.length,
                totalAnalyses: requests.length,
                totalCost: batchResult.totalCost,
                totalTime: batchResult.totalTime,
                successRate: batchResult.successCount / requests.length
            };

        } catch (error) {
            console.error('‚ùå Library analysis error:', error);
            return this.createErrorResponse(`Library analysis failed: ${error.message}`);
        }
    }

    /**
     * User preference integration
     */
    async analyzeWithPreferences(bookData, userPreferences, analysisType = 'summary') {
        try {
            // Apply user preferences to template variables
            const enhancedVariables = {
                title: bookData.title,
                author: bookData.author,
                content: bookData.content,
                analysisDepth: userPreferences.analysisDepth || 'standard',
                outputFormat: userPreferences.outputFormat || 'paragraph',
                focusAreas: userPreferences.focusAreas || [],
                includeQuotes: userPreferences.includeQuotes || false,
                targetAudience: userPreferences.targetAudience || 'general'
            };

            // Generate customized prompt
            const templateResult = await this.generateFromTemplate('analysis', analysisType, enhancedVariables);
            
            if (!templateResult.success) {
                return this.createErrorResponse(`Template generation failed: ${templateResult.error}`);
            }

            // Apply user model preferences
            const preferredModel = userPreferences.preferredModel || this.config.defaultModel.name;
            const modelConfig = this.config.models[preferredModel] || this.config.models[this.config.defaultModel.name];

            const request = {
                prompt: templateResult.prompt,
                model: preferredModel,
                maxTokens: Math.min(userPreferences.maxTokens || modelConfig.maxTokens, modelConfig.maxTokens),
                temperature: userPreferences.temperature || this.config.defaultModel.temperature,
                analysisType,
                userPreferences
            };

            const result = await this.completion(request);

            if (result.success) {
                result.personalizedFor = userPreferences;
                result.appliedPreferences = Object.keys(userPreferences);
            }

            return result;

        } catch (error) {
            console.error('‚ùå Personalized analysis error:', error);
            return this.createErrorResponse(`Personalized analysis failed: ${error.message}`);
        }
    }

    /**
     * Batch processing with optimization
     */
    async processBatch(requests, options = {}) {
        if (!this.config.features.enableBatchProcessing) {
            return this.createErrorResponse('Batch processing not enabled');
        }

        try {
            console.log(`üîÑ Processing batch: ${requests.length} requests`);

            const startTime = Date.now();
            const maxConcurrent = options.maxConcurrent || 3;
            const costLimit = options.costLimit || this.config.costLimits.perHour;

            // Optimize batch
            const optimizedBatch = await this.optimizeBatch(requests, options);

            // Process with concurrency control
            const results = [];
            let totalCost = 0;
            let successCount = 0;
            let errorCount = 0;

            for (let i = 0; i < optimizedBatch.batches.length; i++) {
                const batch = optimizedBatch.batches[i];
                
                // Check cost limits
                if (totalCost >= costLimit) {
                    console.warn(`‚ö†Ô∏è Cost limit reached: ${totalCost.toFixed(4)}`);
                    break;
                }

                // Process batch concurrently
                const batchPromises = batch.slice(0, maxConcurrent).map(async (request) => {
                    if (request.bookData) {
                        return await this.analyzeBook(request.bookData, request.analysisType, request.options);
                    } else {
                        return await this.completion(request);
                    }
                });

                const batchResults = await Promise.allSettled(batchPromises);
                
                // Process results
                for (const result of batchResults) {
                    if (result.status === 'fulfilled' && result.value.success) {
                        results.push(result.value);
                        totalCost += result.value.cost || 0;
                        successCount++;
                    } else {
                        results.push({
                            success: false,
                            error: result.reason?.message || 'Unknown error'
                        });
                        errorCount++;
                    }
                }

                // Small delay between batches to respect rate limits
                if (i < optimizedBatch.batches.length - 1) {
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }

            const endTime = Date.now();
            const totalTime = endTime - startTime;

            console.log(`‚úÖ Batch processing completed: ${successCount}/${requests.length} successful`);

            return {
                success: true,
                results,
                totalRequests: requests.length,
                successCount,
                errorCount,
                totalCost: parseFloat(totalCost.toFixed(6)),
                totalTime,
                averageTimePerRequest: Math.round(totalTime / requests.length),
                costPerRequest: parseFloat((totalCost / requests.length).toFixed(6))
            };

        } catch (error) {
            console.error('‚ùå Batch processing error:', error);
            return this.createErrorResponse(`Batch processing failed: ${error.message}`);
        }
    }

    /**
     * Template integration methods
     */
    async generateFromTemplate(category, name, variables) {
        if (!this.promptTemplates) {
            return { success: false, error: 'Prompt templates not available' };
        }

        try {
            const prompt = this.promptTemplates.generatePrompt(category, name, variables);
            
            if (!prompt) {
                return { success: false, error: `Template not found: ${category}/${name}` };
            }

            return {
                success: true,
                prompt,
                category,
                name,
                variables
            };

        } catch (error) {
            console.error('‚ùå Template generation error:', error);
            return { success: false, error: error.message };
        }
    }

    async generateBatchFromTemplates(templates, variables) {
        const results = [];

        for (const template of templates) {
            const result = await this.generateFromTemplate(
                template.category, 
                template.name, 
                variables
            );
            results.push({
                template,
                ...result
            });
        }

        return results;
    }

    /**
     * Cost and token management
     */
    async estimateRequestCost(request) {
        if (!this.tokenManager) {
            return { cost: 0, tokens: 0 };
        }

        try {
            const model = request.model || this.config.defaultModel.name;
            const modelConfig = this.config.models[model];
            
            if (!modelConfig) {
                throw new Error(`Unknown model: ${model}`);
            }

            const promptTokens = await this.tokenManager.countTokens(request.prompt || '');
            const maxCompletionTokens = request.maxTokens || 150;
            const totalTokens = promptTokens + maxCompletionTokens;

            const cost = totalTokens * modelConfig.costPerToken;

            return {
                cost: parseFloat(cost.toFixed(6)),
                promptTokens,
                estimatedCompletionTokens: maxCompletionTokens,
                totalTokens,
                model,
                costPerToken: modelConfig.costPerToken
            };

        } catch (error) {
            console.error('‚ùå Cost estimation error:', error);
            return { cost: 0, tokens: 0, error: error.message };
        }
    }

    async optimizeForModel(request, model) {
        if (!this.tokenManager) {
            return request;
        }

        try {
            const modelConfig = this.config.models[model];
            if (!modelConfig) {
                return request;
            }

            const promptTokens = await this.tokenManager.countTokens(request.prompt);
            const maxAllowedTokens = modelConfig.maxTokens - (request.maxTokens || 150) - 100; // Buffer

            if (promptTokens > maxAllowedTokens) {
                // Chunk the content
                const chunks = await this.tokenManager.chunkText(request.prompt, maxAllowedTokens);
                
                return {
                    ...request,
                    model,
                    prompt: chunks[0], // Use first chunk
                    optimized: true,
                    originalLength: promptTokens,
                    optimizedLength: await this.tokenManager.countTokens(chunks[0]),
                    chunksAvailable: chunks.length
                };
            }

            return {
                ...request,
                model,
                optimized: false
            };

        } catch (error) {
            console.error('‚ùå Model optimization error:', error);
            return request;
        }
    }

    async validateTokenLimits(request) {
        if (!this.tokenManager) {
            return { valid: true };
        }

        try {
            const model = request.model || this.config.defaultModel.name;
            const modelConfig = this.config.models[model];
            
            const promptTokens = await this.tokenManager.countTokens(request.prompt || '');
            const maxTokens = request.maxTokens || 150;
            const totalTokens = promptTokens + maxTokens;

            const valid = totalTokens <= modelConfig.maxTokens;

            return {
                valid,
                promptTokens,
                maxTokens,
                totalTokens,
                limit: modelConfig.maxTokens,
                model
            };

        } catch (error) {
            console.error('‚ùå Token validation error:', error);
            return { valid: false, error: error.message };
        }
    }

    /**
     * Request validation and preparation
     */
    async validateRequest(request) {
        try {
            const errors = [];

            // Required fields
            if (!request.prompt && !request.messages) {
                errors.push('Either prompt or messages is required');
            }

            // Model validation
            const model = request.model || this.config.defaultModel.name;
            if (!this.config.models[model]) {
                errors.push(`Unsupported model: ${model}`);
            }

            // Security validation
            if (this.config.security.enableInputSanitization) {
                const sanitized = await this.sanitizeInput(request);
                if (sanitized.blocked) {
                    errors.push(`Input blocked: ${sanitized.reason}`);
                }
            }

            // Content filtering
            if (this.config.security.enableContentFilter) {
                const filterResult = await this.applyContentFilter(request);
                if (!filterResult.allowed) {
                    errors.push(`Content filtered: ${filterResult.reason}`);
                }
            }

            // Token limits
            const tokenValidation = await this.validateTokenLimits(request);
            if (!tokenValidation.valid) {
                errors.push(`Token limit exceeded: ${tokenValidation.totalTokens}/${tokenValidation.limit}`);
            }

            if (errors.length > 0) {
                return { valid: false, error: errors.join('; ') };
            }

            // Prepare the request
            const preparedRequest = {
                prompt: request.prompt,
                messages: request.messages,
                model: model,
                maxTokens: Math.min(request.maxTokens || 150, this.config.models[model].maxTokens),
                temperature: Math.max(0, Math.min(2, request.temperature || this.config.defaultModel.temperature)),
                topP: request.topP || 1,
                frequencyPenalty: request.frequencyPenalty || 0,
                presencePenalty: request.presencePenalty || 0,
                stream: request.stream || false,
                ...request
            };

            return { valid: true, request: preparedRequest };

        } catch (error) {
            console.error('‚ùå Request validation error:', error);
            return { valid: false, error: error.message };
        }
    }

    /**
     * Rate limiting integration
     */
    async checkRateLimit(request) {  
    if (!this.rateLimiter) {
        return { allowed: true };
    }

    try {
        const rateLimitRequest = {
            model: request.model || this.config.defaultModel.name,  // ‚Üê FIXED: use request.model
            tokens: await this.tokenManager?.countTokens(request.prompt || '') || 0,  // ‚Üê FIXED: use request.prompt
            estimatedCost: (await this.estimateRequestCost(request)).cost,  // ‚Üê FIXED: use request
            priority: request.priority || 'normal'  // ‚Üê FIXED: use request.priority
        };

        return await this.rateLimiter.checkRequest(rateLimitRequest);

    } catch (error) {
        console.error('‚ùå Rate limit check error:', error);
        return { allowed: true }; // Allow on error to avoid blocking
    }
}

    async recordUsage(usage, model) {
        try {
            // Record in token manager
            if (this.tokenManager) {
                this.tokenManager.recordUsage(
                    usage.totalTokens,
                    usage.cost,
                    model,
                    'book_analysis'
                );
            }

            // Record in rate limiter
            if (this.rateLimiter) {
                await this.rateLimiter.makeRequest({
                    model,
                    tokens: usage.totalTokens,
                    estimatedCost: usage.cost
                });
            }

            // Update internal stats
            this.state.totalRequests++;
            this.state.totalCost += usage.cost;
            this.state.totalTokens += usage.totalTokens;

        } catch (error) {
            console.error('‚ùå Usage recording error:', error);
        }
    }

    /**
     * API request building
     */
    async buildAPIRequest(request) {
        const requestId = `openai_${Date.now()}_${Math.random().toString(36).substring(2, 8)}`;

        const body = {
            model: request.model,
            max_tokens: request.maxTokens,
            temperature: request.temperature,
            top_p: request.topP,
            frequency_penalty: request.frequencyPenalty,
            presence_penalty: request.presencePenalty,
            stream: request.stream || false
        };

        // Handle different request types
        if (request.messages) {
            // Chat completion format
            body.messages = request.messages;
            if (request.systemMessage) {
                body.messages.unshift({
                    role: 'system',
                    content: request.systemMessage
                });
            }
        } else {
            // Text completion format (convert to chat)
            body.messages = [
                {
                    role: 'user',
                    content: request.prompt
                }
            ];
        }

        return {
            requestId,
            body
        };
    }

    /**
     * Response processing
     */
    async processSuccessResponse(data, request, costEstimate, responseTime, requestId) {
        try {
            const choice = data.choices?.[0];
            if (!choice) {
                throw new Error('No choices in response');
            }

            const content = choice.message?.content || choice.text || '';
            const finishReason = choice.finish_reason;

            // Calculate actual usage and cost
            const usage = {
                promptTokens: data.usage?.prompt_tokens || costEstimate.promptTokens,
                completionTokens: data.usage?.completion_tokens || 0,
                totalTokens: data.usage?.total_tokens || costEstimate.totalTokens
            };

            const modelConfig = this.config.models[request.model];
            const actualCost = usage.totalTokens * modelConfig.costPerToken;

            return {
                success: true,
                content: content.trim(),
                model: request.model,
                finishReason,
                usage: {
                    ...usage,
                    cost: parseFloat(actualCost.toFixed(6))
                },
                performance: {
                    responseTime,
                    requestId
                },
                metadata: {
                    timestamp: new Date().toISOString(),
                    requestId,
                    analysisType: request.analysisType
                }
            };

        } catch (error) {
            console.error('‚ùå Response processing error:', error);
            return this.createErrorResponse(`Response processing failed: ${error.message}`);
        }
    }

    async handleAPIError(apiResponse, request, requestId) {
        const error = apiResponse.error;
        const errorMessage = apiResponse.userMessage || 'API request failed';

        // Record error
        this.state.errors.push({
            timestamp: new Date().toISOString(),
            requestId,
            error: errorMessage,
            model: request.model
        });

        // Emit error event
        this.eventBus.emit('ai:request:failed', {
            requestId,
            error: errorMessage,
            model: request.model
        });

        return this.createErrorResponse(errorMessage);
    }

    handleRateLimitResponse(rateLimitCheck) {
        return {
            success: false,
            rateLimited: true,
            reason: rateLimitCheck.reason || 'Rate limit exceeded',
            retryAfter: rateLimitCheck.retryAfter || 60,
            queueSize: rateLimitCheck.queueSize || 0
        };
    }

    /**
     * Utility methods
     */
    createErrorResponse(message) {
        return {
            success: false,
            error: message,
            timestamp: new Date().toISOString()
        };
    }

    selectOptimalModel(bookData, analysisType) {
        // Simple model selection logic
        const wordCount = bookData.wordCount || 0;
        const complexAnalyses = ['themes', 'characters', 'literary_devices'];

        if (complexAnalyses.includes(analysisType) || wordCount > 50000) {
            return 'gpt-4';
        }

        return 'gpt-3.5-turbo';
    }

    calculateOptimalTokens(analysisType) {
        const tokenMap = {
            'summary': 200,
            'themes': 300,
            'characters': 400,
            'difficulty': 150,
            'sentiment': 100
        };

        return tokenMap[analysisType] || 200;
    }

    getAnalysisTemperature(analysisType) {
        const temperatureMap = {
            'summary': 0.3,
            'themes': 0.5,
            'characters': 0.7,
            'difficulty': 0.1,
            'sentiment': 0.2
        };

        return temperatureMap[analysisType] || 0.5;
    }

    async optimizeBatch(requests, options) {
        // Simple batch optimization - group by model
        const batches = [];
        const modelGroups = {};

        for (const request of requests) {
            const model = request.model || this.config.defaultModel.name;
            if (!modelGroups[model]) {
                modelGroups[model] = [];
            }
            modelGroups[model].push(request);
        }

        for (const [model, modelRequests] of Object.entries(modelGroups)) {
            // Split into smaller batches
            const batchSize = options.batchSize || 5;
            for (let i = 0; i < modelRequests.length; i += batchSize) {
                batches.push(modelRequests.slice(i, i + batchSize));
            }
        }

        return { batches };
    }

    aggregateLibraryResults(results, books) {
        const libraryResults = {};

        for (const book of books) {
            libraryResults[book.id] = {
                book: {
                    id: book.id,
                    title: book.title,
                    author: book.author
                },
                analyses: {}
            };
        }

        for (const result of results) {
            if (result.success && result.bookData) {
                const bookId = result.bookData.id;
                const analysisType = result.analysisType;
                
                if (libraryResults[bookId]) {
                    libraryResults[bookId].analyses[analysisType] = result;
                }
            }
        }

        return libraryResults;
    }

    updatePerformanceMetrics(responseTime) {
        this.state.performance.responseTimes.push(responseTime);
        
        // Keep only last 100 response times
        if (this.state.performance.responseTimes.length > 100) {
            this.state.performance.responseTimes.shift();
        }

        // Update metrics
        const times = this.state.performance.responseTimes;
        this.state.performance.averageResponseTime = Math.round(
            times.reduce((sum, time) => sum + time, 0) / times.length
        );
        this.state.performance.minResponseTime = Math.min(...times);
        this.state.performance.maxResponseTime = Math.max(...times);
    }

    /**
     * Security and validation methods
     */
    async validateAPIKey() {
        try {
            // Simple validation - check if key format is correct
            const apiKey = this.config.apiKey;
            
            if (!apiKey || apiKey.length < 20) {
                return { valid: false, message: 'API key is too short' };
            }

            if (!apiKey.startsWith('sk-')) {
                return { valid: false, message: 'API key format is invalid' };
            }

            return { valid: true, message: 'API key format is valid' };

        } catch (error) {
            return { valid: false, message: error.message };
        }
    }

    async sanitizeInput(request) {
        try {
            let prompt = request.prompt || '';
            let blocked = false;
            let reason = '';

            // Remove potentially harmful content
            const originalLength = prompt.length;
            
            // Remove script tags
            prompt = prompt.replace(/<script.*?<\/script>/gi, '');
            
            // Remove excessive repetition
            if (prompt.length > this.config.security.maxPromptLength) {
                prompt = prompt.substring(0, this.config.security.maxPromptLength);
                reason += 'Prompt truncated due to length. ';
            }

            // Check for potential injection attempts
            const injectionPatterns = [
                /ignore\s+previous\s+instructions/i,
                /system\s*:\s*you\s+are/i,
                /\[INST\]/i,
                /\<\|system\|\>/i
            ];

            for (const pattern of injectionPatterns) {
                if (pattern.test(prompt)) {
                    blocked = true;
                    reason += 'Potential prompt injection detected. ';
                    break;
                }
            }

            const sanitized = originalLength !== prompt.length;

            return {
                prompt,
                blocked,
                reason: reason.trim(),
                sanitized,
                originalLength,
                finalLength: prompt.length
            };

        } catch (error) {
            console.error('‚ùå Input sanitization error:', error);
            return {
                prompt: request.prompt || '',
                blocked: true,
                reason: 'Sanitization error'
            };
        }
    }

    async applyContentFilter(request) {
        try {
            const content = request.prompt || '';
            const blockedTerms = [
                'illegal activities',
                'explicit violence',
                'hate speech',
                'personal information',
                'private data'
            ];

            for (const term of blockedTerms) {
                if (content.toLowerCase().includes(term)) {
                    return {
                        allowed: false,
                        reason: `Content contains blocked term: ${term}`,
                        filtered: true
                    };
                }
            }

            return {
                allowed: true,
                reason: null,
                filtered: false
            };

        } catch (error) {
            console.error('‚ùå Content filtering error:', error);
            return {
                allowed: false,
                reason: 'Content filtering error'
            };
        }
    }

    /**
     * Monitoring and statistics
     */
    getUsageStats() {
        return {
            totalRequests: this.state.totalRequests,
            totalCost: parseFloat(this.state.totalCost.toFixed(6)),
            totalTokens: this.state.totalTokens,
            errorCount: this.state.errors.length,
            errorRate: this.state.totalRequests > 0 ? 
                parseFloat((this.state.errors.length / this.state.totalRequests).toFixed(4)) : 0,
            averageCostPerRequest: this.state.totalRequests > 0 ? 
                parseFloat((this.state.totalCost / this.state.totalRequests).toFixed(6)) : 0,
            averageTokensPerRequest: this.state.totalRequests > 0 ? 
                Math.round(this.state.totalTokens / this.state.totalRequests) : 0
        };
    }

    getPerformanceStats() {
        return {
            ...this.state.performance,
            requestCount: this.state.totalRequests,
            uptime: this.state.initialized ? Date.now() - this.initTime : 0
        };
    }

    getHealthStatus() {
        const usageStats = this.getUsageStats();
        const performanceStats = this.getPerformanceStats();
        
        const issues = [];
        
        // Check error rate
        if (usageStats.errorRate > 0.1) {
            issues.push('High error rate detected');
        }
        
        // Check response time
        if (performanceStats.averageResponseTime > 10000) {
            issues.push('High response times detected');
        }
        
        // Check if service is initialized
        if (!this.state.initialized) {
            issues.push('Service not properly initialized');
        }

        return {
            healthy: issues.length === 0,
            status: issues.length === 0 ? 'operational' : 'degraded',
            issues,
            lastCheck: new Date().toISOString(),
            uptime: performanceStats.uptime,
            usage: usageStats,
            performance: performanceStats
        };
    }

    getActiveAlerts() {
        const alerts = [];
        const usageStats = this.getUsageStats();
        
        // Cost alerts
        if (this.state.totalCost > this.config.costLimits.perDay * 0.8) {
            alerts.push({
                type: 'cost_warning',
                severity: 'warning',
                message: `Daily cost approaching limit: ${this.state.totalCost.toFixed(4)}`,
                timestamp: Date.now()
            });
        }
        
        // Error rate alerts
        if (usageStats.errorRate > 0.1) {
            alerts.push({
                type: 'error_rate',
                severity: 'warning',
                message: `High error rate: ${(usageStats.errorRate * 100).toFixed(1)}%`,
                timestamp: Date.now()
            });
        }
        
        return alerts;
    }

    /**
     * Configuration and settings
     */
    applyUserSettings(settings) {
        try {
            const applied = [];
            
            if (settings.preferredModel && this.config.models[settings.preferredModel]) {
                this.config.defaultModel.name = settings.preferredModel;
                applied.push('preferredModel');
            }
            
            if (settings.defaultTemperature !== undefined) {
                this.config.defaultModel.temperature = Math.max(0, Math.min(2, settings.defaultTemperature));
                applied.push('defaultTemperature');
            }
            
            if (settings.maxCostPerRequest !== undefined) {
                this.config.costLimits.perRequest = Math.max(0, settings.maxCostPerRequest);
                applied.push('maxCostPerRequest');
            }
            
            if (settings.apiKey && settings.apiKey !== this.config.apiKey) {
                this.config.apiKey = settings.apiKey;
                // Update authorization header
                this.defaultOptions.headers['Authorization'] = `Bearer ${settings.apiKey}`;
                applied.push('apiKey');
            }

            console.log(`‚öôÔ∏è Applied user settings: ${applied.join(', ')}`);
            
            return {
                success: true,
                applied,
                message: `Applied ${applied.length} settings`
            };

        } catch (error) {
            console.error('‚ùå Settings application error:', error);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Advanced features for future enhancement
     */
    async processStreamingResponse(apiRequest) {
        // Placeholder for streaming implementation
        // This would handle Server-Sent Events from OpenAI
        return [
            { content: 'Streaming ', tokens: 2 },
            { content: 'response ', tokens: 2 },
            { content: 'chunk.', tokens: 2 }
        ];
    }

    async processConcurrent(requests, maxConcurrent = 3) {
        const results = [];
        const processing = [];
        
        for (let i = 0; i < requests.length; i++) {
            // Start request
            const promise = this.completion(requests[i]);
            processing.push({ promise, index: i });
            
            // If we've reached max concurrent or end of requests
            if (processing.length >= maxConcurrent || i === requests.length - 1) {
                // Wait for all current requests to complete
                const batchResults = await Promise.allSettled(
                    processing.map(p => p.promise)
                );
                
                // Process results in order
                for (let j = 0; j < batchResults.length; j++) {
                    const result = batchResults[j];
                    results[processing[j].index] = result.status === 'fulfilled' 
                        ? result.value 
                        : { success: false, error: result.reason?.message };
                }
                
                // Clear processing array
                processing.length = 0;
                
                // Small delay between batches
                if (i < requests.length - 1) {
                    await AsyncUtils.delay(500);
                }
            }
        }
        
        return {
            results,
            maxConcurrentUsed: Math.min(maxConcurrent, requests.length)
        };
    }

    async processWithPriority(requests) {
        // Sort by priority
        const priorityOrder = { high: 3, normal: 2, low: 1 };
        const sortedRequests = [...requests].sort((a, b) => {
            const aPriority = priorityOrder[a.priority] || 2;
            const bPriority = priorityOrder[b.priority] || 2;
            return bPriority - aPriority;
        });
        
        const results = [];
        for (const request of sortedRequests) {
            const result = await this.completion(request);
            results.push(result);
            
            // Small delay between requests
            await new Promise(resolve => setTimeout(resolve, 200));
        }
        
        return {
            processingOrder: sortedRequests,
            results
        };
    }

    /**
     * Cleanup and resource management
     */
    async cleanup() {
        try {
            console.log('üßπ Cleaning up OpenAI service...');
            
            // Clear performance data
            this.state.performance.responseTimes = [];
            
            // Keep only recent errors (last 10)
            this.state.errors = this.state.errors.slice(-10);
            
            // Emit cleanup event
            this.eventBus.emit('ai:service:cleanup', {
                service: 'OpenAI',
                requestsProcessed: this.state.totalRequests,
                totalCost: this.state.totalCost
            });
            
            console.log('‚úÖ OpenAI service cleanup completed');
            
            return { success: true };

        } catch (error) {
            console.error('‚ùå Cleanup error:', error);
            return { success: false, error: error.message };
        }
    }

    async shutdown() {
        try {
            console.log('üõë Shutting down OpenAI service...');
            
            // Export final statistics
            const finalStats = {
                totalRequests: this.state.totalRequests,
                totalCost: this.state.totalCost,
                totalTokens: this.state.totalTokens,
                uptime: Date.now() - (this.initTime || Date.now())
            };
            
            // Clear all state
            this.state.initialized = false;
            
            // Emit shutdown event
            this.eventBus.emit('ai:service:shutdown', {
                service: 'OpenAI',
                finalStats
            });
            
            console.log('‚úÖ OpenAI service shutdown completed', finalStats);
            
            return { success: true, finalStats };

        } catch (error) {
            console.error('‚ùå Shutdown error:', error);
            return { success: false, error: error.message };
        }
    }

    /**
     * Export data for debugging and analysis
     */
    exportServiceData() {
        return {
            metadata: {
                exportedAt: new Date().toISOString(),
                serviceVersion: '1.0.0',
                uptime: this.state.initialized ? Date.now() - this.initTime : 0
            },
            configuration: {
                // Don't export sensitive data
                defaultModel: this.config.defaultModel,
                models: Object.keys(this.config.models),
                features: this.config.features,
                costLimits: this.config.costLimits
            },
            statistics: {
                usage: this.getUsageStats(),
                performance: this.getPerformanceStats(),
                health: this.getHealthStatus()
            },
            recentErrors: this.state.errors.slice(-10),
            alerts: this.getActiveAlerts()
        };
    }

    /**
     * Testing and development helpers
     */
    async runHealthCheck() {
        const startTime = Date.now();
        
        try {
            // Test basic completion
            const testResult = await this.completion({
                prompt: 'Test prompt for health check',
                model: 'gpt-3.5-turbo',
                maxTokens: 10
            });
            
            const responseTime = Date.now() - startTime;
            
            return {
                healthy: testResult.success,
                responseTime,
                testResult,
                timestamp: new Date().toISOString()
            };

        } catch (error) {
            return {
                healthy: false,
                error: error.message,
                responseTime: Date.now() - startTime,
                timestamp: new Date().toISOString()
            };
        }
    }

    // Development mode helpers
    enableDebugMode() {
        this.debugMode = true;
        console.log('üîß OpenAI service debug mode enabled');
    }

    disableDebugMode() {
        this.debugMode = false;
        console.log('üîß OpenAI service debug mode disabled');
    }

    getDebugInfo() {
        if (!this.debugMode) {
            return { debugMode: false };
        }

        return {
            debugMode: true,
            state: { ...this.state },
            config: {
                // Safe config without sensitive data
                defaultModel: this.config.defaultModel,
                features: this.config.features,
                costLimits: this.config.costLimits
            },
            dependencies: {
                tokenManager: !!this.tokenManager,
                rateLimiter: !!this.rateLimiter,
                promptTemplates: !!this.promptTemplates
            }
        };
    }
}

// Helper functions for creating service instances with different configurations
export function createOpenAIService(config) {
    return new OpenAIService(config);
}

export function createDevelopmentOpenAIService(apiKey) {
    return new OpenAIService({
        apiKey,
        defaultModel: 'gpt-3.5-turbo',
        timeout: 15000,
        retries: 2,
        maxCostPerRequest: 0.10,
        maxCostPerHour: 2.00,
        maxCostPerDay: 10.00,
        enableStreaming: true,
        enableBatchProcessing: true,
        enableContentFiltering: true,
        enableCostTracking: true
    });
}

export function createProductionOpenAIService(apiKey) {
    return new OpenAIService({
        apiKey,
        defaultModel: 'gpt-4',
        timeout: 30000,
        retries: 3,
        maxCostPerRequest: 1.00,
        maxCostPerHour: 50.00,
        maxCostPerDay: 200.00,
        enableStreaming: true,
        enableBatchProcessing: true,
        enableContentFiltering: true,
        enableCostTracking: true,
        enableInputSanitization: true,
        enableContentFilter: true
    });
}

// Export for global access in development/testing
if (typeof window !== 'undefined') {
    window.OpenAIService = OpenAIService;
    window.createOpenAIService = createOpenAIService;
}

/**
 * INTEGRATION WITH BOOK BUDDY ARCHITECTURE
 * ========================================
 * 
 * This OpenAIService implementation follows your established patterns:
 * 
 * ‚úÖ EXTENDS APIService: Inherits retry logic, timeout handling, error recovery
 * ‚úÖ EVENTBUS INTEGRATION: Uses your EventBus for component communication
 * ‚úÖ UTILITY INTEGRATION: Works with AITokenManager, AIRateLimiter, AIPromptTemplates
 * ‚úÖ ERROR HANDLING: Follows your standardized error response format
 * ‚úÖ SINGLE RESPONSIBILITY: Focused on OpenAI API integration and book analysis
 * ‚úÖ MODULAR STRUCTURE: Clean separation of concerns with helper methods
 * ‚úÖ CONSOLE LOGGING: Uses your emoji-based logging style
 * ‚úÖ ASYNC/AWAIT: Consistent with your codebase patterns
 * ‚úÖ CONFIGURATION: Flexible configuration matching your service pattern
 * 
 * NEXT STEPS FOR INTEGRATION:
 * 
 * 1. Add to app.js constructor:
 *    ```javascript
 *    import OpenAIService from './modules/services/OpenAIService.js';
 *    
 *    // In constructor after other services
 *    this.openAIService = new OpenAIService({
 *        apiKey: 'your-openai-api-key'
 *    });
 *    
 *    // Initialize with dependencies
 *    await this.openAIService.initialize(
 *        this.aiTokenManager,
 *        this.aiRateLimiter, 
 *        this.aiPromptTemplates
 *    );
 *    ```
 * 
 * 2. Add to global exports at bottom of app.js:
 *    ```javascript
 *    window.OpenAIService = OpenAIService;
 *    ```
 * 
 * 3. Use in your application:
 *    ```javascript
 *    // Analyze a book
 *    const analysis = await this.openAIService.analyzeBook(bookData, 'summary');
 *    
 *    // Process multiple books
 *    const libraryAnalysis = await this.openAIService.analyzeLibrary(books);
 *    
 *    // Custom completion
 *    const result = await this.openAIService.completion({
 *        prompt: 'Analyze this book...',
 *        model: 'gpt-4',
 *        maxTokens: 500
 *    });
 *    ```
 * 
 * The service is fully compatible with your Week 3 AI features and ready for production use!
 */